# Rafael Valle

**{Polymath, Pioneer, Prophet} Ã— Superintelligence in Multimodal Generation and Understanding**

San Francisco Bay Area  
rafaelvalle@berkeley.edu  
LinkedIn: [https://www.linkedin.com/in/vallerafael](https://www.linkedin.com/in/vallerafael)    
Website: [https://rafaelvalle.github.io/](https://rafaelvalle.github.io/)  
Google Scholar: [https://scholar.google.com/citations?user=SktxU8IAAAAJ&hl=en](https://scholar.google.com/citations?user=SktxU8IAAAAJ&hl=en)

---

## Executive Highlights

* **Frontier Strategy:** Pioneered 0â†’1 multimodal capabilities that evolved into cross-organizational foundations at **Meta** and **NVIDIA**.
* **Organizational Leadership:** Scaled NVIDIAâ€™s ADLR-AGI (Audio General Intelligence) research organization from **3 to 13 scientists**, setting the technical bar, research scope, and long-horizon direction for the group.
* **Technical Architecture:** Architected the audio/audio-visual data and evaluation infrastructure for ðŸ¥‘ (Frontier LLM), establishing new company-wide standards.
* **Technical Advisor:** Serving as the primary technical advisor for audio-visual generation and editing Technical Advisor: Serving as the primary technical advisor for audio-visual generation and editing in ðŸ¥­ (Multimodal Generation).
* **Vision Alignment:** Partnered with NVIDIA leadership to establish multimodal general intelligence spanning audio and video as a core pillar of NVIDIA's flagship models.
* **Global Impact:** Delivered foundational generative models with **25M+ downloads**, with external adoption by tier-1 technology companies.

---

## Selected Publications

- [**UALM: Unified Audio Language Model for Understanding, Generation and Reasoning**](https://arxiv.org/abs/2510.12000)  
- [**Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models**](https://arxiv.org/abs/2507.08128)  
- [**Fugatto: Foundational Generative Audio Transformer Opus 1**](https://iclr.cc/virtual/2025/poster/30598) 
- [**OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM**](https://arxiv.org/abs/2510.15870)  
- [**Koel-TTS: Enhancing LLM based Speech Generation with Preference Alignment and Classifier Free Guidance**](https://arxiv.org/abs/2502.05236)

---

## Work Experience

### Meta â€” Superintelligence Labs (MSL)
**Research Scientist** Â· July 2024 â€” Present

#### Strategic Data & Model Infrastructure
* **Architected the complete audio/audio-visual data foundation for ðŸ¥‘ ** (Frontier LLM), transforming nascent capability into a company-wide standard.
* **Pioneered captioning and data sourcing strategies** now used across understanding and generation models to ensure modality independence and prevent capability trivialization.
* Built multi-stage pipelines orchestrating models to maximize information extraction and data quality at frontier scale.
* Contributed to model codebase, identifying and resolving critical issues affecting training stability for next-generation systems.

#### Specialized Consulting & Strategic Direction (ðŸ¥­)
* **Serving as the primary technical subject matter expert** for audio generation and editing within ðŸ¥­ (Frontier Multimodal Generation).
* **Guiding all stages of training**â€”from initial data strategy and architectural ideation to fine-tuningâ€”consulting with non-specialist teams to bridge the gap between audio research and scalable multimodal engineering.
* **Defined evaluation frameworks for Projects Avocado and Mango**, determining what audio-visual intelligence means organizationally and shaping long-horizon research priorities.
* Developed assessment systems and demonstrations that shifted internal consensus on technical approaches for controllable audio synthesis.

#### Quality Systems & Engineering
* Engineered scalable quality control mechanisms for multimodal data across all training phases.
* Designed strategies identifying data issues at scale with significant precision improvements for frontier-class models.
* Daily collaboration with researchers from ex-OpenAI, ex-Google DeepMind, and ex-xAI on the integration of audio-visual reasoning into unified world models.

---

### NVIDIA â€” ADLR-AGI  
**Research Manager / Research Scientist** Â· October 2017 â€“ July 2024 Â· Santa Clara, CA

#### Strategic Direction & Organizational Impact
* **Partnered with leadership** to transform audio general intelligence from non-strategic to a core company pillar within 18 months, establishing audio as foundational to NVIDIA's multimodal future.
* **Initiated NVIDIA's strategic shift** from TTS-centric pipelines to audio general intelligence (2023), an initiative that directly informed the company-level roadmap.
* **Scaled the research organization** from 3 to 13 research scientists, personally setting the technical bar and long-horizon direction for the group.
* Secured large-scale compute access and cross-organizational partnerships during periods of constrained resources to ensure frontier-level experimentation.

#### Technical Achievements & Flagship Integration
* **Built and owned the audio intelligence stack for Nemotron** (NVIDIA's flagship LLM), including data acquisition, large-scale labeling pipelines, architectures, and training recipes.
* Achieved frontier results within six months of strategic pivot: unified models for speech/music, large-scale labeling infra, and interactive systems described as the first "ChatGPT moment" for audio.
* Established internal benchmarks that became reference evaluations across major external labs.

#### Industry Partnerships & External Adoption
* Established research collaboration with **Universal Music Group** to bridge frontier AI capabilities with music industry stakeholders.
* Built foundational generative models (WaveGlow, Flowtron, RAD-TTS) establishing NVIDIA's early leadership in neural synthesis, multimodal understanding (Audio Flamingo 3, OmniVinci), and Audio Generation (Fugatto, ETTA).
* **External Impact:** BigVGAN reaching 25M+ downloads; WaveGlow integrated by tier-1 technology companies; Fugatto featured on CNBC's *Mad Money*.


---

## Education

**University of California, Berkeley**  
PhD, Machine Listening and Improvisation Â· 2013â€“2018  
Designated Emphasis in Computational and Data Science & Engineering

**Hochschule fÃ¼r Musik und Darstellende Kunst Stuttgart**  
MSc, Computer Music / Composition Â· 2009â€“2011

**Universidade Federal do Rio de Janeiro**  
BMus, Orchestral Conducting & Music Performance Â· 2004â€“2009
