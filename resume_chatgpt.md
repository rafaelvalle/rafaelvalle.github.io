# Rafael Valle

**Research Leader in Multimodal AI & Audio General Intelligence**  
Architect of frontier audio systems at Meta & NVIDIA

San Francisco Bay Area  
rafaelvalle@berkeley.edu  
LinkedIn: https://www.linkedin.com/in/vallerafael  
Website: https://rafaelvalle.github.io  
Google Scholar: https://scholar.google.com/citations?user=SktxU8IAAAAJ  

---

## Executive Summary

Research leader driving frontier multimodal intelligence with a track record of turning nascent capabilities into core organizational infrastructure.

At **Meta Superintelligence Labs**, architected company-wide audio/audio-visual data and evaluation foundations for next-generation multimodal models.  
At **NVIDIA**, transformed audio from narrow TTS into a strategic pillar of multimodal general intelligence, building the audio stack for flagship LLMs and scaling a high-impact research organization.

Delivered foundational models with **25M+ downloads**, adopted by tier-1 technology companies and integrated into production-scale AI systems.

---

## Selected Publications

- **UALM: Unified Audio Language Model for Understanding, Generation and Reasoning** — arXiv  
- **Audio Flamingo 3: Fully Open Large Audio Language Models** — arXiv  
- **Fugatto: Foundational Generative Audio Transformer Opus 1** — ICLR 2025  
- **OmniVinci: Omni-Modal Understanding LLM Architecture & Data** — arXiv  
- **Koel-TTS: Preference-Aligned Speech Generation** — arXiv  

---

## Experience

### Meta — Superintelligence Labs (MSL)  
**Research Scientist** · July 2024 – Present

#### Frontier Data & Infrastructure

- Architected the complete audio/audio-visual data foundation for Meta’s frontier multimodal models, transforming early experimentation into company-wide standard infrastructure  
- Designed scalable multi-stage pipelines orchestrating models for high-precision captioning, labeling, and information extraction  
- Established sourcing strategies ensuring modality-independent learning while preventing capability shortcutting  

#### Evaluation & Research Direction

- Built evaluation frameworks that became the organizational standard for measuring audio and audio-visual intelligence across frontier models  
- Created capability-focused benchmarks distinguishing genuine reasoning and generation from superficial performance  
- Developed technical demonstrations that reshaped internal research direction and architectural choices  

#### Quality Systems & Engineering

- Engineered scalable quality control systems across training phases, significantly improving data reliability  
- Contributed to model codebases, identifying and resolving stability-critical training issues  

---

### NVIDIA — ADLR-AGI  
**Research Manager / Research Scientist** · October 2017 – July 2024

#### Strategic Transformation & Leadership

- Led NVIDIA’s pivot from TTS-centric pipelines to **Audio General Intelligence**, elevating audio into a core pillar of the company’s multimodal AI strategy within 18 months  
- Scaled the ADLR-AGI research organization from **3 to 13 scientists**, setting technical standards, research scope, and long-term direction  
- Secured large-scale compute and cross-org partnerships during resource-constrained periods to sustain frontier-level experimentation  

#### Flagship Systems & Architecture

- Built and owned the complete audio intelligence stack being used in **Nemotron**, NVIDIA’s flagship LLM  
  - data acquisition & large-scale labeling infrastructure  
  - multimodal architectures for speech, music, and audio-visual reasoning  
  - training recipes and evaluation systems  

- Achieved frontier results within six months of strategic shift, including unified audio models and interactive multimodal systems internally described as NVIDIA’s first “ChatGPT moment” for audio  
- Established internal benchmarks that became reference evaluations across external research labs  

#### Industry Impact & Adoption

- Led research collaboration with **Universal Music Group** bridging frontier AI and music industry workflows  
- Built foundational generative and multimodal models including **WaveGlow, Flowtron, RAD-TTS, Audio Flamingo, OmniVinci, Fugatto**  

- **External Impact:**  
  - BigVGAN — 25M+ downloads  
  - WaveGlow integrated by tier-1 technology companies  
  - Fugatto featured on CNBC’s *Mad Money*  

---

## Education

**University of California, Berkeley**  
PhD — Machine Listening and Improvisation (2013–2018)  
Designated Emphasis: Computational & Data Science & Engineering  

**Hochschule für Musik und Darstellende Kunst Stuttgart**  
MSc — Computer Music / Composition (2009–2011)  

**Universidade Federal do Rio de Janeiro**  
BMus — Orchestral Conducting & Music Performance (2004–2009)
