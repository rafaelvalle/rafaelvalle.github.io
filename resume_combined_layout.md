# Rafael Valle

**Research Leader in Superintelligence | Multimodal Generation & Understanding**

San Francisco Bay Area  
rafaelvalle@berkeley.edu  
[LinkedIn](https://www.linkedin.com/in/vallerafael) · [Website](https://rafaelvalle.github.io) · [Google Scholar](https://scholar.google.com/citations?user=SktxU8IAAAAJ)

---

## Executive Summary

Research leader who transforms nascent capabilities into organizational foundations. Track record of 0→1 technical initiatives that became strategic pillars at **Meta** and **NVIDIA**.

**At Meta Superintelligence Labs:** Architected the complete audio/audio-visual data foundation for frontier multimodal models; serving as primary technical expert guiding audio generation strategy across understanding and synthesis workstreams.

**At NVIDIA:** Drove the company's strategic pivot from TTS-centric pipelines to Audio General Intelligence, building the audio stack for flagship LLMs and scaling a high-impact research organization from 3 to 13 scientists.

Delivered foundational models with **25M+ downloads**, adopted by tier-1 technology companies. Research featured on CNBC's *Mad Money*.

---

## Experience

### Meta — Superintelligence Labs (MSL)

**Research Scientist | Technical Lead, Audio & Audio-Visual Foundations**  
July 2024 – Present

#### Frontier Data & Model Infrastructure

- Architected the complete audio/audio-visual data foundation for Meta's flagship frontier LLM, transforming early experimentation into company-wide standard infrastructure
- Designed scalable multi-stage pipelines orchestrating models for high-precision captioning, labeling, and information extraction at frontier scale
- Established data sourcing strategies ensuring modality-independent learning while preventing capability shortcuts
- Contributed to model codebase, identifying and resolving stability-critical training issues for next-generation systems

#### Technical Strategy & Research Direction

- Serving as primary technical subject matter expert for audio generation and editing within frontier multimodal generation efforts
- Directing all stages of training—from initial data strategy and architectural ideation to fine-tuning—bridging audio research and scalable multimodal engineering
- Defined evaluation frameworks that became the organizational standard for measuring audio-visual intelligence, shaping long-horizon research priorities
- Developed assessment systems and demonstrations that shifted internal consensus on technical approaches for controllable audio synthesis

#### Quality Systems & Cross-Functional Leadership

- Engineered scalable quality control systems across training phases, achieving significant precision improvements in data reliability
- Daily collaboration with researchers from ex-OpenAI, ex-Google DeepMind, and ex-xAI on integrating audio-visual reasoning into unified world models

---

### NVIDIA — ADLR-AGI

**Research Manager / Research Scientist**  
October 2017 – July 2024 · Santa Clara, CA

#### Strategic Transformation & Organizational Leadership

- Partnered with executive leadership to transform audio general intelligence from a specialized niche into a core pillar of NVIDIA's multimodal AI strategy within 18 months
- Initiated NVIDIA's strategic shift from TTS-centric pipelines to audio general intelligence (2023), directly informing the company-level roadmap
- Scaled the ADLR-AGI research organization from 3 to 13 scientists, setting technical standards, research scope, and long-horizon direction

#### Flagship Systems & Technical Architecture

- Built and owned the complete audio intelligence stack for **Nemotron** (NVIDIA's flagship LLM): data acquisition and large-scale labeling infrastructure, multimodal architectures for speech, music, and audio-visual reasoning, training recipes and evaluation systems
- Achieved frontier results within six months of strategic pivot: unified audio models and interactive multimodal systems internally described as NVIDIA's first "ChatGPT moment" for audio
- Established internal benchmarks that became reference evaluations across major external research labs

#### Industry Impact & External Adoption

- Forged research collaboration with **Universal Music Group**, integrating frontier AI with creative industry workflows
- Pioneered foundational generative models including **WaveGlow, Flowtron, RAD-TTS, BigVGAN, Audio Flamingo, OmniVinci, Fugatto**
- **External Impact:** BigVGAN achieved 25M+ downloads; WaveGlow integrated into production stacks of tier-1 technology companies; Fugatto featured on CNBC's *Mad Money*

---

## Selected Publications

- **UALM: Unified Audio Language Model for Understanding, Generation and Reasoning** — [arXiv](https://arxiv.org/abs/2510.12000)
- **Audio Flamingo 3: Fully Open Large Audio Language Models** — [arXiv](https://arxiv.org/abs/2507.08128)
- **Fugatto: Foundational Generative Audio Transformer Opus 1** — [ICLR 2025](https://iclr.cc/virtual/2025/poster/30598)
- **OmniVinci: Omni-Modal Understanding LLM Architecture & Data** — [arXiv](https://arxiv.org/abs/2510.15870)
- **Koel-TTS: Preference-Aligned Speech Generation** — [arXiv](https://arxiv.org/abs/2502.05236)

---

## Education

**University of California, Berkeley**  
PhD — Machine Listening and Improvisation (2013–2018)  
*Designated Emphasis: Computational & Data Science & Engineering*

**Hochschule für Musik und Darstellende Kunst Stuttgart**  
MSc — Computer Music / Composition (2009–2011)

**Universidade Federal do Rio de Janeiro**  
BMus — Orchestral Conducting & Music Performance (2004–2009)